{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Συμπερασματολογία και Επικύρωση (Inference and Validation)\n",
    "\n",
    "Τώρα που έχετε ένα εκπαιδευμένο δίκτυο, μπορείτε να το χρησιμοποιήσετε για να κάνετε προβλέψεις. Η διαδικασία αυτή συνήθως λέγετε **συμπερασματολογία**/**inference**, ένας όρος που δανειστήκαμε από τη στατιστική. Παρόλα αυτά, τα νευρωνικά δίκτυα έχουν την τάση να λειτουργούν *υπερβολικά καλά* στα δεδομένα εκπαίδευσης αλλά δεν μπορούν να γενικεύσουν σε δεδομένα που δεν έχουν ξαναδεί. Το πρόβλημα αυτό ονομάζεται **υπερπροσαρμογή**/**overfitting** και μειώνει την απόδοση των συμπερασμάτων του δικτύου. Για να ελέγξω για υπερπροσαρμογή κατά την εκπαίδευση, μετρούμε την απόδοση σε δεδομένα που δεν εμπεριέχονται στα δεδομένα εκπαίδευσης τα οποία ονομάζονται δεδομένα επαλήθευσης/επικύρωσης **validation**. Μειώνουμε την υπερπροσαρμογή μέσω κανονικοποίησης (regularization) όπως με χρήση dropout (Περιορισμός Ενεργοποίησης Κόμβων) ενώ while παρακολουθώ την απόδοση επικύρωσης (validation performance) κατά τη διάρκεια της εκπαίδευσης. Σε αυτό το notebook, θα δούμε πως μπορούμε να το επιτύχουμε αυτό με τη χρήση της PyTorch.\n",
    "\n",
    "Όπως συνήθως, ξεκινάμε με το να φορτώσουμε τα δεδομένα μας μέσω της torchvision. Θα δούμε περισσότερες λεπτομέρειες για τη torchvision και πως φορτώνουμε τα δεδομένα μας σε επόμενο στάδιο. Σε αυτό το παράδειγμα θα εκμεταλλευτώ τα δεδομένα ελέγχου τα οποία μπορούμε να πάρουμε με την επιλογή `train=False` όπως παρακάτω:\n",
    "\n",
    "```python\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "```\n",
    "\n",
    "Το σετ των δεδομένων ελέγχου περιλαμβάνει εικόνες όπως του σετ εκπαίδευσης. Συνήθως θα δείτε οτι ένα 10-20% του αρχικού dataset δεσμεύεται για να αποτελέσει τα σετ των δεδομένων ελέγχου και επικύρωσης, ενώ το υπόλοιπο ποσοστό αποτελεί τα δεδομένα εκπαίδευσης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Καθορίστε ένα μετασχηματισμό για τη κανονικοποίηση των δεδομένων\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Κατεβάστε και φορτώστε τα δεδομένα εκπαίδευσης\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Κατεβάστε και φορτώστε τα δεδομένα ελέγχου\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εδώ θα δημιουργήσω ένα μοντέλο όπως συνήθως, χρησιμοποιώντας το ίδιο μοντέλο με το προηγούμενο notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # μετατρέπω τον τανυστή εισόδου σε διανυσμα γραμμής. Το x.shape[0] είναι ο αριθμός παρτίδας.\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο στόχος της επικυρωσης ειναι να μετρήσει την αποδοση του δικτύου σε δεδομένα τα οποία δεν εμπεριέχονται στο σετ δεδομένων ελεγχου. Η μετρική της απόδοσης σε αυτή τη περίπτωση ορίζεται απο τον προγραμματιστή. Συνήθως ορίζεται ως ακρίβεια, δηλαδή το ποσοστό των κλάσεων που το δίκτυό μας προβλέπει σωστά. Άλλες μετρικές είναι η Ακρίβεια και Ανάκλησης [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) και η αναλογία σφάλματος στο πρώτα 5 αποτελέσματα (top-5 error rate). Ε΄δω θα επικρεντρωθουμε στην ακρίβεια (accuracy). Πρώτα κάνω ένα πέρασμα προς το εμπρός με μία παρτίδα απο το σετ ελέγχου."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# Υπολόγισε τις πιθανότητες καθε κλάσης\n",
    "ps = torch.exp(model(images))\n",
    "# Κάνω έναν έλεγχο εαν έχει σωστή μορφή ο τανυστής, πρέπει να έχουμε πιθανότητες και για τις 10 κλάσεις για τις 64 εικόνες\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μέσω των πιθανοτήτων, μπορώ να πάρω τη πιο πιθανή κλάση χρησιμοποιώντας τη μέθοδο `ps.topk`. Αυτή επιστρέφει τις $k$ υψηλότερες τιμές. Καθώς θέλω να πάρω την πιο πιθανή κλάση, χρησιμοποιώ `ps.topk(1)`, η οποία επιστρέφει τις top-$k$ τιμές και τους top-$k$ δείκτες. Αν η υψηλότερη τιμή είναι στο πέμπτο στοιχείο, θα λάβουμε τον δείκτη 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Ψάξε για τις πιο πιθανές κλάσεις στα 10 πρώτα δείγματα\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα μπορώ να ελέγξω εάν οι κλάσεις που έχουν προβλεφθεί είναι ίδιες με τις ετικέτες των εικόνων αυτών. Αυτό μπορώ να το πετύχω εύκολα με την ισότητα μεταξύ `top_class` και `labels`, αλλα πρέπει να ήμαστε προσεκτικοί με τις διαστάσεις. Εδώ η `top_class` είναι ένας τανυστής 2D με μέγεθος `(64, 1)` ενώ η `labels` είναι 1D με μέγεθος `(64)`. Για να δουλέψει σωστά ο έλεγχος ισότητας όπως θέλουμε, πρέπει οι `top_class` και `labels` να έχουν το ίδιο μέγεθος.\n",
    "\n",
    "Αν εκτελέσω\n",
    "\n",
    "```python\n",
    "equals = top_class == labels\n",
    "```\n",
    "\n",
    "η `equals` θα έχει μέγεθος `(64, 64)`, δοκιμάστε το. Αυτό που κάνει είναι να συγκρίνει το πρώτο στοιχείο σε κάθε γραμμή της `top_class` μ κάθε στοιχείο της `labels` και επιστρέφει 64 True/False boolean τιμές για κάθε γραμμή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα πρέπει να υπολογίσω το ποσοστό των σωστών προβλέψεων. Η `equals` έχει binary τιμές, είτε 0 είτε 1. Αυτο σημάινει οτι αν απλα αθροίσουμε όλες τις τιμές και τις διαιρέσουμε με τον αριθμό των τιμών, θα πάρουμε το ποσοστό των σωστών προβλέψεων. Αυτό ειναι η ίδια πράξη με το να παίρναμε τη μέση τιμή, οπότε μπορούμε να πάρουμε την ακρίβεια καλώντας την `torch.mean`. Μακάρι όμως να ήταν τοσο απλό. Αν το δοκιμάσετε με `torch.mean(equals)`, θα λάβεται ένα σφάλμα\n",
    "\n",
    "```\n",
    "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
    "```\n",
    "\n",
    "Αυτό συμβαίνει γιατι η `equals` έχει τύπο `torch.ByteTensor` αλλά η `torch.mean` δεν υποστηρίζει τανυστές αυτού του είδους. Οπότε πρέπει να μετατρέψουμε την `equals` σε τανυστή float. Προσέξτε οτι οταν εκτελώ την `torch.mean` επιστρέφει ενα τανυστή scalar, για να λάβω την πραγματική τιμή ως float πρέπει να εκτελέσουμε `accuracy.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το δίκτυο δεν έχει εκπαιδευτεί ακόμα οπότε κάνει τυχαίες προβλέψεις με αποτέλεσμα όντως να βλέπουμε μία ακρίβεια περίπου στο 10%. Τώρα ας εκπαιδεύσουμε το δίκτυό μας και να συμπεριλάβουμε ένα πέρασμα επικύρωσης έτσι ώστε να μπορέσουμε να υπολογίσουμε πόσο καλά αποδίδει το δίκτυό μας στο σετ ελέγχου. Από τη στιγμή που δεν θα κάνω update των παραμέτρων στο βήμα επικύρωσης, μπορούμε να επιταχύνουμε τη διαδικασία απενεργοποιώντας τις παραγώγους με την `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "# απενεργοποιώ τις παραγώγους\n",
    "with torch.no_grad():\n",
    "    # βήμα επικύρωσης\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "```\n",
    "\n",
    ">**Άσκηση:** Εφαρμόστε τον βρόχο επικύρωσης παρακάτω. Μπορείτε σε μεγάλο βαθμό να αντιγράψετε και να επικολλήσετε τον κώδικα από πάνω, αλλά προτείνω να τον πληκτρολογήσετε εσείς καθώς είναι απαραίτητο να αναπτύξετε τις δεξιότητές σας. Σε γενικές γραμμές, θα μαθαίνετε πάντα περισσότερα με το να γράφετε τον κώδικα και όχι να τον αντιγράφετε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Απενεργοποιώ τις παραγωγους στο βρόχο επικύρωσης καθώς μου απελευθερώνει μνήμη και απαιτεί λιγότερες πράξεις\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Εποχή: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Υπερπροσαρμογή (Overfitting)\n",
    "\n",
    "Αν παρατηρήσουμε τις απώλειες (σφαλμα) της εκπαίδευσης και της επικύρωσης καθώς εκπαιδεύουμε το δίκτυο, θα παρατηρήσουμε ένα φαινομενο το οποίο είναι γνωστό ως υπερπροσαρμογή (overfitting).\n",
    "\n",
    "<img src='assets/overfitting.png' width=450px>\n",
    "\n",
    "Το δίκτυο μαθαίνει το σετ εκπαίδευσης όλο και καλύτερα, με αποτέλεσμα χαμηλές απώλειες εκπαίδευσης. Παρόλα αυτά, αρχίζει και έχει προβλήματα γενίκευσης σε δεδομένα εκτός του σετ εκπαίδευσης με αποτέλεσμα οι απώλειες επικύρωσης να αυξάνουν. Ο απώτερος στόχος κάθε νευρωνικού δικτύου είναι να κάνει σωστές προβλέψεις σε νέα δεδομένα, οπότε θα πρέπει πάση θυσία να έχουμε οσο το δυνατό χαμηλότερο σφάλμα επικύρωσης. Μία λύση είναι να χρησιμοποιήσουμε την έκδοση του δικτύου εκείνη στις οποίες οι παράμετροί του δίνουν το χαμηλότερο σφάλμα επικύρωσης, στο συγκεκριμένο παράδειγμα μεταξύ της εποχής 8-10. Αυτή η στρατηγική ονομάζεται *πρόωρη διακοπή*/*early-stopping*. Στη πράξη, σώζουμε το δίκτυό μας συχνά καθώς το εκπαιδεύουμε και αργότερα επιλέγουμε το μοντέλο με το χαμηλότερο σφάλμα επικύρωσης.\n",
    "\n",
    "Η πιο διαδεδομένη τεχνική για να αποφεύγουμε το φαινόμενο της υπερπροσαρμογής (πέραν της πρόωρης διακοπής) είναι το dropout (Περιορισμός Ενεργοποίησης κόμβων), όπου τυχαία απενεργοποιούμε κόμβους εισόδου. Αυτή η τεχνική αναγκάζει το δίκτυο να μοιράζεται τη πληροφορία σε όλα τα βάρη, αυξάνοντας την ικανότητα γενίκευσης σε νέα δεδομένα. Η εφαρμογή dropout στη PyTorch είναι πολύ απλή χρησιμοποιώντας την μέθοδο nn.Dropout. [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout με 0.2 πιθανότητα απενεργοποίησης κόμβων \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #  μετατρέπω τον τανυστή εισόδου σε διανυσμα γραμμής\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Εφαρμογή dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # έξοδος, οπότε δεν χρησιμοποιώ εδώ dropout\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "Κατά την εκπαίδευση θέλουμε να χρησιμοποιήσουμε dropout για την αποφυγή υπερπροσαρμογής, αλλά κατά τη διαδικασία συμπερασματολογίας θέλουμε να χρησιμοποιήσουμε όλο το δίκτυο. Οπότε πρέπει να απενεργοποιήσω το dropout κατά την επικύρωση και τον έλεγχο, και φυσικά όποτε χρησιμοποιώ το δίκτυο για προβλέψεις. Για να το πετύχω αυτό, χρησιμοποιώ την `model.eval()`. Η εντολή αυτή προσαρμόζει το μοντέλο μας σε κατάσταση αξιολόγησης όπου η πιθανότητα dropout είναι 0. Μπορείτε να επαναφέρετε το dropout πίσω ορίζοντας το μοντέλο σας σε κατάσταση εκπαίδευσης με την `model.train()`. Γενικά, το πλάνο για το βρόχο επικύρωσης θα είναι όπως παρακάτω, όπου απενεργοποιείτε τις παραγώγους, βάζετε το μοντέλο σας σε κατάσταση αξιολόγησης, υπολογίζετε το σφάλμα επικύρωσης και τη μετρική, και επιστρέφετε το μοντέλο σας πίσω σε κατάσταση εκπαίδευσης.\n",
    "\n",
    "```python\n",
    "# απενεργοποίηση παραγώγων\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # ορίστε το μοντέλο σας σε κατασταση επικύρωσης\n",
    "    model.eval()\n",
    "    \n",
    "    # βρόχος επίκύρωσης\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "\n",
    "# επαναφέρετε ξανα το μοντέλο σε κατασταση εκπαίδευσης\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Άσκηση:** Εφαρμόστε τη στρατηγική dropout στο μοντέλο σας και εκπαιδεύστε το ξανά στο Fashion-MNIST. Δείτε εάν επιτυγχάνεται χαμηλότερο σφάλμα επικύρωσης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # μονάδα Dropout (Περιορισμός Ενεργοποίησης) με 0.2 πιθανότητα απόρριψης\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # βεβαιωθείτε οτι ο τανυστής εισόδου έχει \"ισοπεδωθεί\" (flattened) ή αλλιώς έχει γίνει γραμμή\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Χρήση dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # έξοδος, οπότε δεν χρησιμοποιώ εδώ dropout\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Απενεργοποιώ τις παραγώγους για την επικύρωση για λιγότερη μνήμη και υπολογισμούς\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Εποχή: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συμπερασματολογία/Inference\n",
    "\n",
    "Τώρα που το μοντέλο είναι εκπαιδευμένο, μπορούμε να το χρησιμοποιήσουμε για προβλέψεις. Το έχουμε ξανακάνει, αλλά τώρα πρέπει να θυμηθούμε να βάλουμε το μοντέλο μας σε κατάσταση συμπερασματολογίας με την εντολή `model.eval()`. Επίσης πρέπει να απενεργοποιήσουμε το autograd με την `torch.no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εισαγωγή του helper module (υπάρχει στον υποφάκελο)\n",
    "import helper\n",
    "\n",
    "# Ελέξτε το δικτυό σας!\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Μετετρεψε την 2D εικόνα σε 1D διάνυσμα\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Υπολόγισε τις πιθανότητες κλάσης (softmax) για την img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Εμφάνισε την εικόνα και τις πιθανότητες\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Στη συνέχεια!\n",
    "\n",
    "Στο επόμενο μέρος, θα δούμε πώς μπορούμε να αποθηκεύσουμε τα εκπαιδευμένα μας δίκτυα. Στη πραγματικότητα, δεν θέλουμε να εκπαιδεύουμε το δίκτυό μας κάθε φορά που θέλουμε να το χρησιμοποιήσουμε. Αντί αυτού, το εκπαιδεύουμε μόνο μία φορά, το αποθηκεύουμε, και στη συνέχεια το φορτώνουμε όταν θέλουμε να το εκπαιδεύσουμε περισσότερο ή να το χρησιμοποιήσουμε για συμπερασματολογία."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό το notebook 📖 δημιουργήθηκε για το μάθημα ***Υπολογιστική Νοημοσύνη και Μηχανική Μάθηση*** του Τμήματος Μηχανικών Παραγωγής και Διοίκησης, της Πολυτεχνικής Σχολής του Δημοκριτείου Πανεπιστημίου Θράκης.<br>\n",
    "This notebook is made available under the Creative Commons Attribution [(CC-BY)](https://creativecommons.org/licenses/by/4.0/legalcode) license. Code is also made available under the [MIT License](https://opensource.org/licenses/MIT).<br>\n",
    "Author: Asst. Prof. Angelos Amanatiadis\n",
    "<img src=\"assets/cc.png\" style=\"width:55px; float: right; margin: 0px 0px 0px 0px;\"></img>\n",
    "<img src=\"assets/mit.png\" style=\"width:40px; float: right; margin: 0px 10px 0px 0px;\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
