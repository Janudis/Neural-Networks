{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μεταφορά Μάθησης (Transfer Learning)\n",
    "\n",
    "Σε αυτό το notebook, θα μάθετε πώς να χρησιμοποιείτε προ-εκπαιδευμένα δίκτυα για την επίλυση απαιτητικών προβλημάτων όρασης υπολογιστή. Συγκεκριμένα, θα χρησιμοποιείτε δίκτυα εκπαιδευμένα στο dataset [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
    "\n",
    "Το ImageNet είναι ένα τεράστιο σύνολο δεδομένων με πάνω από 1 εκατομμύριο εικόνες απο 1000 κατηγορίες. Χρησιμοποιείται για να εκπαιδεύσει βαθιά νευρωνικά δίκτυα χρησιμοποιώντας μια αρχιτεκτονική που ονομάζεται συνελικτικά στρώματα. Δεν πρόκειται να μπούμε σε αυτο το notebook στις λεπτομέρειες των συνελικτικών δικτύων καθώς θα τα αναλύσουμε σε επόμενο μάθημα.\n",
    "\n",
    "Μόλις εκπαιδευτούν, αυτά τα μοντέλα λειτουργούν εκπληκτικά, ως ανιχνευτές χαρακτηριστικών (feature detectors) για εικόνες στις οποίες δεν εκπαιδεύτηκαν. Η χρήση ενός προ-εκπαιδευμένου δικτύου σε εικόνες που δεν εχουν συμπεριληθεί στο σύνολο των εικόνων εκπαίδευσης ονομάζεται μεταφορά μάθησης. Εδώ θα χρησιμοποιήσουμε την μεταφορά μάθησης για να εκπαιδεύσουμε ένα δίκτυο που θα μπορεί να ταξινομεί φωτογραφίες γάτας και σκύλου με σχεδόν τέλεια ακρίβεια.\n",
    "\n",
    "Μέσω του `torchvision.models` μπορείτε να κατεβάσετε αυτά τα προ-εκπαιδευμένα δίκτυα και να τα χρησιμοποιήσετε στις εφαρμογές σας. Θα συμπεριλάβουμε πλέον και τα `models` στα imports μας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τα περισσότερα από τα προ-εκπαιδευμένα μοντέλα απαιτούν την είσοδο εικόνων με ανάλυση 224x224. Επίσης, θα πρέπει να αντιστοιχίσουμε την κανονικοποίηση που χρησιμοποιήθηκε κατά την εκπαίδευση αυτών των μοντέλων. Κάθε κανάλι χρώματος κανονικοποιήθηκε ξεχωριστά, με τις μέσες τιμές να είναι `[0,448, 0,456, 0,406]` και οι τυπικές αποκλίσεις να είναι `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# Συμπληρώστε: Ορίστε τους μετασχηματισμούς για τα δεδομένα εκπαίδευσης και τα δεδομένα ελέγχου\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Περάστε τους μετασχηματισμούς εδώ και, στη συνέχεια, εκτελέστε το επόμενο κελί για να δείτε πώς φαίνονται οι μετασχηματισμοί\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορούμε να φορτώσουμε ένα μοντέλο όπως το [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Ας εμφανίσουμε την αρχιτεκτονική του μοντέλου για να δούμε τι συμβαίνει."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό το μοντέλο είναι κατασκευασμένο από δύο κύρια μέρη, τα χαρακτηριστικά και τον ταξινομητή. Το τμήμα χαρακτηριστικών είναι μια στοίβα συνελικτικών επιπέδων και λειτουργεί συνολικά ως ανιχνευτής χαρακτηριστικών που μπορεί να τροφοδοτηθεί σε έναν ταξινομητή. Το τμήμα του ταξινομητή είναι ένα ενιαίο πλήρως συνδεδεμένο επίπεδο `(classifier): Linear (in_features = 1024, out_features = 1000)`. Αυτό το επίπεδο εκπαιδεύτηκε στο σύνολο δεδομένων ImageNet, οπότε δεν θα λειτουργήσει για το συγκεκριμένο πρόβλημα. Αυτό σημαίνει ότι πρέπει να αντικαταστήσουμε τον ταξινομητή, αλλά τα χαρακτηριστικά θα λειτουργούν τέλεια από μόνα τους. Σε γενικές γραμμές, θεωρώ τα προ-εκπαιδευμένα δίκτυα ως εκπληκτικά καλούς ανιχνευτές χαρακτηριστικών που μπορούν να χρησιμοποιησω ως είσοδο σε απλούς ταξινομητές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Παγώνω\" τις παραμέτρους, ώστε να μην αλλάζουν κατα το backpropagation\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Με δομημένο πλέον το μοντέλο μας, πρέπει να εκπαιδεύσουμε τον ταξινομητή. Ωστόσο, τώρα χρησιμοποιούμε ένα **πραγματικά βαθύ** νευρωνικό δίκτυο. Εάν προσπαθήσετε να το εκπαιδεύσετε σε μια CPU όπως συνήθως, θα χρειαστεί πολύ πολύ χρόνος. Αντ 'αυτού, θα χρησιμοποιήσουμε την GPU για να κάνουμε τους υπολογισμούς. Οι γραμμικοί υπολογισμοί άλγεβρας γίνονται παράλληλα στην GPU που οδηγεί σε 100νταπλάσιες ταχύτητες εκπαίδευσης. Είναι επίσης δυνατό να εκπαιδεύσετε το δίκτυο σε πολλές GPU, μειώνοντας περαιτέρω τον χρόνο εκπαίδευσης.\n",
    "\n",
    "Η PyTorch, όπως επίσης και κάθε άλλη library/framework βαθιάς μάθησης, χρησιμοποιεί [CUDA] (https://developer.nvidia.com/cuda-zone) για να υπολογίζει αποτελεσματικά τα βήματα πρόσω και πίσω τροφοδότησης στην GPU. Στη PyTorch, μπορούμε να μεταφέρουμε τις παραμέτρους του μοντέλου μας και άλλους τανυστές στη μνήμη GPU χρησιμοποιώντας την εντολή `model.to('cuda')`. Μπορείτε να τα μεταφέρετε πίσω στην CPU με την `model.to('cpu')` εντολή που θα εκτελείτε συνήθως όταν θα πρέπει να χρησιμοποιήσετε την έξοδο του δικτύου σας εκτός PyTorch. Ως απόδειξη της αυξημένης ταχύτητας, θα συγκρίνω πόσο χρόνο χρειάζεται για να εκτελέσουμε ένα βήμα προς τα εμπρός και πίσω με και χωρίς GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in ['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Εκπαιδεύστε μόνο τις παραμέτρους ταξινομητή, οι παράμετροι των χαρακτηριστικών έχουν παγώσει\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Μετακινήστε την είσοδο και τις ετικέτες στην GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορείτε να γράψετε device agnostic code που θα χρησιμοποιεί αυτόματα τη CUDA εάν είναι ενεργοποιημένη οπως παρακάτω:\n",
    "\n",
    "```python\n",
    "# στην αρχή του κώδικα\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# έπειτα όποτε παίρνετε ένα νέο τανυστή ή Module \n",
    "# δεν θα τα αντιγράφει εάν βρίσκονται ήδη στον επιθυμητό επεξεργαστή\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "Από εδώ, θα σας αφήσω να ολοκληρώσετε την εκπαίδευση του μοντέλου. Η διαδικασία είναι η ίδια όπως πριν, εκτός του ότι τώρα το μοντέλο σας είναι πολύ πιο ισχυρό. Θα πρέπει να επιτύχετε εύκολα ακρίβεια μεγαλύτερη από 95%.\n",
    "\n",
    ">**Άσκηση:** Εκπαιδεύστε προ-εκαπιδευμένα μοντέλα για να ταξινομήσετε εικόνες γάτας και σκύλου. Συνεχίστε με το μοντέλο DenseNet ή δοκιμάστε το ResNet, το οποίο είναι επίσης ένα καλό μοντέλο για να δοκιμάσετε. Βεβαιωθείτε ότι εκπαιδεύετε μόνο τον ταξινομητή και ότι οι παράμετροι για το τμήμα των χαρακτηριστικών έχουν παγώσει."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αν δεν υπάρχει GPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# \"Παγώστε\" τις παραμέτρους, ώστε να μην αλλάζουν κατα το backpropagation\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.classifier = nn.Sequential(nn.Linear(1024, 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(256, 2),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Εκπαιδεύστε μόνο τις παραμέτρους του ταξινομητή, οι παράμετροι των χαρακτηριστικών έχουν παγώσει\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Μετακινήστε τις εισόδου και τις ετικέτες στον προεπιλεγμένο επεξεργαστή\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Υπολογίστε την ακρίβεια\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "            print(f\"Εποχή {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό το notebook 📖 δημιουργήθηκε για το μάθημα ***Υπολογιστική Νοημοσύνη και Μηχανική Μάθηση*** του Τμήματος Μηχανικών Παραγωγής και Διοίκησης, της Πολυτεχνικής Σχολής του Δημοκριτείου Πανεπιστημίου Θράκης.<br>\n",
    "This notebook is made available under the Creative Commons Attribution [(CC-BY)](https://creativecommons.org/licenses/by/4.0/legalcode) license. Code is also made available under the [MIT License](https://opensource.org/licenses/MIT).<br>\n",
    "Author: Asst. Prof. Angelos Amanatiadis\n",
    "<img src=\"assets/cc.png\" style=\"width:55px; float: right; margin: 0px 0px 0px 0px;\"></img>\n",
    "<img src=\"assets/mit.png\" style=\"width:40px; float: right; margin: 0px 10px 0px 0px;\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
